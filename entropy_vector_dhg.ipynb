{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Entropy Vector for Hypergraphs (DHG)\n",
    "\n",
    "Implementation of the entropy vector $SE(H)$ from *\"A New Entropy for Hypergraphs\"*, using the [DeepHypergraph](https://github.com/iMoonLab/DeepHypergraph) library.\n",
    "\n",
    "The entropy vector is a $2^m - 1$ dimensional descriptor built by computing Shannon entropy over all partial hypergraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from math import comb\n",
    "from dhg import Hypergraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-core",
   "metadata": {},
   "source": [
    "## 1. Core Entropy Function $S(H)$\n",
    "\n",
    "Given a `dhg.Hypergraph`:\n",
    "\n",
    "1. Extract the incidence matrix $I = H^T$ (shape $m \\times n$) from `hg.H_T`\n",
    "2. Compute $L(H) = I \\cdot I^T$ where $L_{i,j} = |e_i \\cap e_j|$\n",
    "3. Eigendecompose, normalize: $\\mu_i = \\lambda_i / \\mathrm{Tr}(L)$\n",
    "4. Shannon entropy: $S(H) = -\\sum \\mu_i \\log_2(\\mu_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "core-entropy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(hg):\n",
    "    \"\"\"Compute Shannon entropy S(H) for a dhg.Hypergraph.\n",
    "\n",
    "    Args:\n",
    "        hg: dhg.Hypergraph instance.\n",
    "\n",
    "    Returns:\n",
    "        entropy: float, Shannon entropy in bits.\n",
    "    \"\"\"\n",
    "    # H_T is (num_e, num_v) — the incidence matrix I\n",
    "    I = hg.H_T.to_dense()\n",
    "\n",
    "    # L(H) = I * I^T, entry (i,j) = |e_i ∩ e_j|\n",
    "    L = I @ I.T\n",
    "\n",
    "    eigenvalues = torch.linalg.eigvalsh(L)\n",
    "\n",
    "    # Filter out zero/negative eigenvalues (numerical noise)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 1e-12]\n",
    "\n",
    "    trace = eigenvalues.sum()\n",
    "    if trace < 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    mu = eigenvalues / trace\n",
    "    entropy = torch.sum(-mu * torch.log2(mu)).item() #The paper shows log2 in the equation but their results imply they used log10\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-vector",
   "metadata": {},
   "source": [
    "## 2. Entropy Vector $SE(H)$\n",
    "\n",
    "Iterate over all $2^m - 1$ non-empty subsets of hyperedges, grouped by subset size.\n",
    "For each subset, build a partial `dhg.Hypergraph` and compute its entropy.\n",
    "Sort entropies in increasing order within each scale, then concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entropy-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_vector(hg):\n",
    "    \"\"\"Compute the full entropy vector SE(H) for a dhg.Hypergraph.\n",
    "\n",
    "    Args:\n",
    "        hg: dhg.Hypergraph instance.\n",
    "\n",
    "    Returns:\n",
    "        se: np.ndarray of length 2^m - 1.\n",
    "    \"\"\"\n",
    "    edge_list = hg.e[0]  # list of tuples\n",
    "    m = hg.num_e\n",
    "    n = hg.num_v\n",
    "\n",
    "    se = []\n",
    "    for size in range(1, m + 1):\n",
    "        entropies = []\n",
    "        for subset_indices in combinations(range(m), size):\n",
    "            partial_edges = [list(edge_list[i]) for i in subset_indices]\n",
    "            partial_hg = Hypergraph(n, partial_edges)\n",
    "            entropies.append(compute_entropy(partial_hg))\n",
    "        entropies.sort()\n",
    "        se.extend(entropies)\n",
    "\n",
    "    return np.array(se)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-example",
   "metadata": {},
   "source": [
    "## 3. Example\n",
    "\n",
    "A small hypergraph with 6 vertices and 3 hyperedges:\n",
    "- $e_0 = \\{0, 1, 2\\}$\n",
    "- $e_1 = \\{1, 2, 3\\}$\n",
    "- $e_2 = \\{3, 4, 5\\}$\n",
    "\n",
    "With $m=3$ we get $2^3 - 1 = 7$ entries in the entropy vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-build",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hg = Hypergraph(6, [[0, 1, 2], [1, 2, 3], [3, 4, 5]])\n",
    "# hg = Hypergraph(6, [[0, 1, 2], [0,3], [0,4,5]])\n",
    "\n",
    "hg = Hypergraph(6, [[0,1,2], [3,4], [4,5]])\n",
    "\n",
    "print(f\"Vertices: {hg.num_v}, Hyperedges: {hg.num_e}\")\n",
    "print(f\"Edge list: {hg.e[0]}\")\n",
    "print(f\"Vertex degrees: {hg.deg_v}\")\n",
    "print(f\"Edge sizes: {hg.deg_e}\")\n",
    "\n",
    "\n",
    "# Incidence matrix I = H_T (m x n)\n",
    "I = hg.H_T.to_dense()\n",
    "print(f\"\\nIncidence matrix I (H_T), shape {list(I.shape)}:\")\n",
    "print(I)\n",
    "\n",
    "# Intersection matrix L = I * I^T\n",
    "L = I @ I.T\n",
    "print(f\"\\nIntersection matrix L = I * I^T:\")\n",
    "print(L)\n",
    "print(f\"|e0 ∩ e1| = {int(L[0,1])}, |e0 ∩ e2| = {int(L[0,2])}, |e1 ∩ e2| = {int(L[1,2])}\")\n",
    "\n",
    "hg.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-entropy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full hypergraph entropy\n",
    "S_full = compute_entropy(hg)\n",
    "print(f\"S(H) for full hypergraph: {S_full:.4f} bits\")\n",
    "\n",
    "# Entropy vector\n",
    "se = entropy_vector(hg)\n",
    "print(f\"\\nEntropy vector SE(H) ({len(se)} entries):\")\n",
    "\n",
    "idx = 0\n",
    "for size in range(1, hg.num_e + 1):\n",
    "    count = comb(hg.num_e, size)\n",
    "    block = se[idx:idx + count]\n",
    "    print(f\"  Size {size} ({count} subsets): {np.round(block, 4)}\")\n",
    "    idx += count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-verify",
   "metadata": {},
   "source": [
    "## 4. Verify Against NumPy Implementation\n",
    "\n",
    "Cross-check with the raw numpy implementation from `entropy_vector.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy_numpy(incidence_matrix):\n",
    "    \"\"\"Reference numpy implementation.\"\"\"\n",
    "    L = incidence_matrix @ incidence_matrix.T\n",
    "    eigenvalues = np.linalg.eigvalsh(L)\n",
    "    eigenvalues = eigenvalues[eigenvalues > 1e-12]\n",
    "    trace = eigenvalues.sum()\n",
    "    if trace < 1e-12:\n",
    "        return 0.0\n",
    "    mu = eigenvalues / trace\n",
    "    return -np.sum(mu * np.log2(mu))\n",
    "\n",
    "def entropy_vector_numpy(hyperedges, num_vertices):\n",
    "    \"\"\"Reference numpy implementation.\"\"\"\n",
    "    m = len(hyperedges)\n",
    "    I_np = np.zeros((m, num_vertices), dtype=np.float64)\n",
    "    for i, edge in enumerate(hyperedges):\n",
    "        for v in edge:\n",
    "            I_np[i, v] = 1.0\n",
    "    se = []\n",
    "    for size in range(1, m + 1):\n",
    "        entropies = []\n",
    "        for subset_indices in combinations(range(m), size):\n",
    "            entropies.append(compute_entropy_numpy(I_np[list(subset_indices), :]))\n",
    "        entropies.sort()\n",
    "        se.extend(entropies)\n",
    "    return np.array(se)\n",
    "\n",
    "se_np = entropy_vector_numpy([[0,1,2], [3,4], [4,5]], 6)\n",
    "print(f\"DHG:   {np.round(se, 4)}\")\n",
    "print(f\"NumPy: {np.round(se_np, 4)}\")\n",
    "print(f\"Match: {np.allclose(se, se_np)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
